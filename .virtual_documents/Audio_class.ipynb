import os
import matplotlib.pyplot as plt
import tensorflow as tf
import librosa


CAPUCHIN_FILE = 'data/Parsed_Capuchinbird_Clips/XC114131-0.wav'
NOT_CAPUCHIN_FILE = 'data/Parsed_Not_Capuchinbird_Clips/afternoon-birds-song-in-forest-0.wav'


file_contents = tf.io.read_file(CAPUCHIN_FILE)
wav, sample_rate = librosa.load(CAPUCHIN_FILE, sr=None)
sample_rate


wav.shape


wav = librosa.resample(wav, orig_sr=sample_rate, target_sr=16000)
len(wav)


def load_wav_16k_mono(filename):
    # Convert TensorFlow tensor to string (file path)
    filepath = tf.constant(filename)
    filepath = filepath.numpy().decode('utf-8')

    # Load wav file
    wav, sample_rate = librosa.load(filepath, sr=None)

    # Resample the audio to the desired sample rate (e.g., 16000 Hz)
    wav = librosa.resample(wav, orig_sr=sample_rate, target_sr=16000)
    
    return wav


wave = load_wav_16k_mono(CAPUCHIN_FILE)
nwave = load_wav_16k_mono(NOT_CAPUCHIN_FILE)


plt.plot(wave)
plt.plot(nwave)
plt.show()
print('\nThe Blue WaveForm is the Capuchin Audio and the Orange is the Non-Capuchin Audio')
print('By using this as the chosen decoder we can build a CNN vision model to look at the WaveForms to make predictions')


POS = 'data/Parsed_Capuchinbird_Clips'
NEG = 'data/Parsed_Not_Capuchinbird_Clips'


pos = tf.data.Dataset.list_files(POS+'/*.wav')
neg = tf.data.Dataset.list_files(NEG+'/*.wav')


pos.as_numpy_iterator().next()


positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))
negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))
data = positives.concatenate(negatives)


data


data.as_numpy_iterator().next()


lengths = []
for file in os.listdir(POS):
  tensor_wave = load_wav_16k_mono(POS + '/' + file)
  lengths.append(len(tensor_wave))

lengths[0:10]


print(f'Mean Length: {tf.math.reduce_mean(lengths).numpy()}\nMin Length: {tf.math.reduce_min(lengths).numpy()}\nMax Length: {tf.math.reduce_max(lengths).numpy()}')


print(f'At 16000Hz this means our average Capuchin Clip is about {54156/16000} seconds long')


def preprocess(file_path, label):
    # Define a helper function to process each file path
    def _process_file(file_path):
        # Convert the tensor to a string
        file_path_str = file_path.numpy().decode('utf-8')

        # Load wav file
        wav = load_wav_16k_mono(file_path_str)

        # Pad the waveform if necessary
        wav = wav[:48000]  # Grab the first 3 seconds of each clip
        zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)  # Pad shorter clips with zeros
        wav = tf.concat([zero_padding, wav], 0)

        # Compute the spectrogram
        spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)
        spectrogram = tf.abs(spectrogram)
        spectrogram = tf.expand_dims(spectrogram, axis=2)

        return spectrogram

    # Apply the processing function to each file path
    processed_data = tf.py_function(_process_file, [file_path], tf.float32)
    processed_data.set_shape((1491, 257, 1))  # Set the shape of the spectrogram tensor
    return processed_data, label



filepath, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()


spectrogram, label = preprocess(filepath, label)


plt.figure(figsize=(30,20))
plt.imshow(tf.transpose(spectrogram)[0])


filepath, label = negatives.shuffle(buffer_size=10000).as_numpy_iterator().next()
spectrogram, label = preprocess(filepath, label)
plt.figure(figsize=(30,20))
plt.imshow(tf.transpose(spectrogram)[0])


data = data.map(preprocess)
print(data)
data = data.cache()
data = data.shuffle(1000)
data = data.batch(16)
data = data.prefetch(8)


train_size = round(len(data) * .7) #Find what 70% of the data is for splitting


train = data.take(train_size)
test = data.skip(train_size).take(len(data)-train_size)
len(train), len(test), len(data)


samples, labels = train.as_numpy_iterator().next()


samples.shape, labels.shape


from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Dense, Flatten


model = Sequential([
    Conv2D(16, (3,3), activation='relu', input_shape=(1491,257,1)),
    Conv2D(16, (3,3), activation='relu'),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.binary_crossentropy, metrics=[tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])

model.summary()


hist = model.fit(train, epochs=5, validation_data=test)


plt.title('Loss')
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.show()


plt.title('Precision')
plt.plot(hist.history['precision'])
plt.plot(hist.history['val_precision'])
plt.show()


plt.title('Recall')
plt.plot(hist.history['recall'])
plt.plot(hist.history['val_recall'])
plt.show()





X_test, y_test = test.as_numpy_iterator().next()


y_pred = model.predict(X_test)


y_pred = [1 if prediction > 0.5 else 0 for prediction in y_pred]
y_test.astype('int')[:10],y_pred[:10]





def load_wav_16k_mono(filename):
    # Convert TensorFlow tensor to string (file path)
    filepath = tf.constant(filename)
    filepath = filepath.numpy().decode('utf-8')

    # Load wav file
    wav, sample_rate = librosa.load(filepath, sr=None)

    # Resample the audio to the desired sample rate (e.g., 16000 Hz)
    wav = librosa.resample(wav, orig_sr=sample_rate, target_sr=16000)
    
    return wav


import pydub
from pydub import AudioSegment
import io

def load_mp3_16k_mono(filename):
    # Read the MP3 file
    audio = AudioSegment.from_mp3(filename)

    # Convert stereo to mono
    audio = audio.set_channels(1)

    # Export as WAV format to an in-memory file-like object
    wav_io = io.BytesIO()
    audio.export(wav_io, format="wav")

    # Read the WAV data from the in-memory object
    wav_io.seek(0)
    wav, sample_rate = librosa.load(wav_io, sr=None)

    # Resample the audio to the desired sample rate (e.g., 16000 Hz)
    wav = librosa.resample(wav, orig_sr=sample_rate, target_sr=16000)
    
    return wav


mp3 = 'data/Forest Recordings/recording_00.mp3'
wav = load_mp3_16k_mono(mp3)


wav.shape, wav[:10]


audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)


samples, index = audio_slices.as_numpy_iterator().next()


preprocess_mp3(samples, index)





len(audio_slices)


def preprocess_mp3(sample, label):
    sample = tf.convert_to_tensor(sample[0])
    # Define a helper function to process each file path
    # Convert the tensor to a string
    zero_padding = tf.zeros([48000] - tf.shape(sample), dtype=tf.float32)  # Pad shorter clips with zeros
    wav = tf.concat([zero_padding, sample], 0)

        # Compute the spectrogram
    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)
    spectrogram = tf.abs(spectrogram)
    spectrogram = tf.expand_dims(spectrogram, axis=2)
    spectrogram.set_shape((1491, 257, 1))

    return spectrogram


audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)
audio_slices = audio_slices.map(preprocess_mp3)
audio_slices = audio_slices.batch(64)


audio_slices


y_pred = model.predict(audio_slices)
y_pred = [1 if prediction > 0.9 else 0 for prediction in y_pred]


y_pred





from itertools import groupby


yhat = [key for key, group in groupby(y_pred)]
calls = tf.math.reduce_sum(yhat).numpy()


yhat, calls


results = {}
for file in os.listdir('data/Forest Recordings/'):
    FILEPATH = os.path.join('data', 'Forest Recordings', file)

    wav = load_mp3_16k_mono(FILEPATH)
    audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)
    audio_slices = audio_slices.map(preprocess_mp3)
    audio_slices = audio_slices.batch(64)

    y_pred = model.predict(audio_slices)

    results[file] = y_pred





class_preds = {}
for file, logits in results.items():
    class_preds[file] = [1 if prediction > 0.9 else 0 for prediction in logits]


class_preds['recording_01.mp3']





total_counts = {}
for file, scores in class_preds.items():
    total_counts[file] = tf.math.reduce_sum([key for key, group in groupby(scores)])
total_counts


total_counts['recording_00.mp3'].numpy()





import csv

# Open the CSV file for writing
with open('capuchin_bird_results.csv', 'w', newline='') as f:
    writer = csv.writer(f, delimiter=',')
    
    # Write the header row
    writer.writerow(['recording', 'capuchin_calls'])
    
    # Iterate over each item in total_counts
    for key, value in total_counts.items():
        # Extract the numpy value if value is a tensor
        if isinstance(value, tf.Tensor):
            value = value.numpy()
        
        # Write the row to the CSV file
        writer.writerow([key, value])






import pandas as pd
df = pd.read_csv('capuchin_bird_results.csv')
df.head()


df = df.sort_values(by='capuchin_calls', axis=0, ascending=False)
df.head()
